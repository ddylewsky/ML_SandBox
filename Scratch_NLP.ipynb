{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Level Look at the Basics of NLP \n",
    "#### This is a notebook based on the NLP chapter in \"Data Science from Scratch\" by Joel Grus. Please check out it out the book here:\n",
    "https://learning.oreilly.com/library/view/data-science-from/9781492041122/\n",
    "\n",
    "#### Or his blog here:\n",
    "https://joelgrus.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the Requests and Beautiful soup livraries to get some data. Here we are going to grab some data from an essay written by Mike Loukides titled \"What is Data Science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "\n",
    "url = \"https://www.oreilly.com/ideas/what-is-data-science\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look a the data we have, we need to get at the article body by finding the div with the class \"main-post-radar-content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"main-post-radar-content\">\n",
       "\n",
       "              \n",
       "              \n",
       "              \n",
       "              \n",
       "              \n",
       "              <p>Weâve all heard it: according to Hal Varian, <a href=\"http://www.nytimes.com/2009/08/06/technology/06stats.html\">statistics is the next sexy job</a>. Five years ago, in <a href=\"http://oreilly.com/web2/archive/what-is-web-20.html\">What is Web 2.0</a>, Tim OâReilly said that âdata is the next Intel Inside.â But what does that statement mean? Why do we suddenly care about statistics and about data?</p>\n",
       "<p>In this post, I examine the many sides of data science â the technologies, the companies and the unique skill sets.</p><div class=\"pqxIa0L9\"><div class=\"inline-cta trial-cta\" id=\"trial-cta\" itemscope=\"\" itemtype=\"http://schema.org/Product\">\n",
       "  <div class=\"thumb\">\n",
       "    <a href=\"https://www.oreilly.com/online-learning/\">\n",
       "      <img class=\"\" itemprop=\"image\" src=\"https://d3ansictanv2wj.cloudfront.net/safari-topic-cta-1f60e6f96856da19ba3cb25660472ca5.jpg\"/>\n",
       "    </a>\n",
       "  </div>\n",
       "  <div class=\"title\">\n",
       "    <h2>\n",
       "      Learn faster. Dig deeper. See farther.\n",
       "    </h2>\n",
       "  </div>\n",
       "   <div class=\"meta\">\n",
       "    <p class=\"dek\">Join the O'Reilly online learning platform. Get a free trial today and find answers on the fly, or master something new and useful.</p>\n",
       "    <a class=\"textCTA-small more\" href=\"https://www.oreilly.com/online-learning/\">Learn more</a>\n",
       "  </div>\n",
       "</div></div>\n",
       "<p>The web is full of âdata-driven apps.â Almost any e-commerce application is a data-driven application. Thereâs a database behind a web front end, and middleware that talks to a number of other databases and data services (credit card processing companies, banks, and so on). But merely using data isnât really what we mean by âdata science.â A data application acquires its value from the data itself, and creates more data as a result. Itâs not just an application with data; itâs a data product. Data science enables the creation of data products.</p>\n",
       "<p>One of the earlier data products on the Web was the <a href=\"http://en.wikipedia.org/wiki/CDDB\">CDDB database</a>. The developers of CDDB realized that any CD had a unique signature, based on the exact length (in samples) of each track on the CD. Gracenote built a database of track lengths, and coupled it to a database of album metadata (track titles, artists, album titles). If youâve ever used iTunes to rip a CD, youâve taken advantage of this database. Before it does anything else, iTunes reads the length of every track, sends it to CDDB, and gets back the track titles. If you have a CD thatâs not in the database (including a CD youâve made yourself), you can create an entry for an unknown album. While this sounds simple enough, itâs revolutionary: CDDB views music as data, not as audio, and creates new value in doing so. Their business is fundamentally different from selling music, sharing music, or analyzing musical tastes (though these can also be âdata productsâ). CDDB arises entirely from viewing a musical problem as a data problem.</p>\n",
       "<p>Google is a master at creating data products. Hereâs a few examples:</p>\n",
       "<ul>\n",
       "<li>Googleâs breakthrough was realizing that a search engine could use input other than the text on the page. Googleâs <a href=\"http://en.wikipedia.org/wiki/PageRank\">PageRank</a> algorithm was among the first to use data outside of the page itself, in particular, the number of links pointing to a page. Tracking links made Google searches much more useful, and PageRank has been a key ingredient to the companyâs success.</li>\n",
       "<li>Spell checking isnât a terribly difficult problem, but by suggesting corrections to misspelled searches, and observing what the user clicks in response, Google made it much more accurate. Theyâve built a dictionary of common misspellings, their corrections, and the contexts in which they occur.</li>\n",
       "<li>Speech recognition has always been a hard problem, and it remains difficult. But Google has made huge strides by using the voice data theyâve collected, and has been able to <a href=\"http://gdgt.com/discuss/voice-recognition-is-amazing-ive-only-68e/\">integrate voice search</a>        into their core search engine.</li>\n",
       "<li>During the Swine Flu epidemic of 2009, Google was able to track the progress of the epidemic <a href=\"http://www.google.org/flutrends/about/how.html\">by following searches for flu-related topics</a>.</li>\n",
       "</ul>\n",
       "<figure><img alt=\"\" src=\"http://s.radar.oreilly.com/2010/06/01/datascience-swing-flu.png\"/><figcaption>Google was able to spot trends in the Swine Flu epidemic roughly two weeks before the Center for Disease Control by analyzing searches that people were making in different regions of the country.</figcaption></figure>\n",
       "<p>Google isnât the only company that knows how to use data. <a href=\"http://www.facebook.com/\">Facebook</a> and <a href=\"http://www.linkedin.com/\">LinkedIn</a> use patterns of friendship relationships to suggest other people you may know, or should<br/>\n",
       "know, with sometimes frightening accuracy. <a href=\"http://www.amazon.com/\">Amazon</a> saves your searches, correlates what you search for with what other users search for, and uses it to create surprisingly appropriate recommendations. These recommendations are âdata productsâ that help to drive Amazonâs more traditional retail business. They come about because Amazon understands that a book isnât just a book, a camera isnât just a camera, and a customer isnât ust a customer; customers generate a trail of âdata exhaustâ that can be mined and put to use, and a camera is a cloud of data that can be correlated with the customersâ behavior, the data they leave every time they visit the site.</p>\n",
       "<p>The thread that ties most of these applications together is that data collected from users provides added value. Whether that data is search terms, voice samples, or product reviews, the users are in a feedback loop in which they contribute to the products they use. Thatâs the beginning of data science.</p>\n",
       "<p>In the last few years, there has been an explosion in the amount of data thatâs available. Whether weâre talking about web server logs, tweet streams, online transaction records, âcitizen science,â data from sensors, government data, or some other source, the problem isnât finding data, itâs figuring out what to do with it. And itâs not just companies using their own data, or the data contributed by their users. Itâs increasingly common to mashup data from a number of sources. â<a href=\"http://oreilly.com/catalog/9780596804787\">Data Mashups in R</a>â analyzes mortgage foreclosures in Philadelphia County by taking a public report from the county sheriffâs office, extracting addresses and using Yahoo to convert the addresses to latitude and longitude, then using the geographical data to place the foreclosures on a map (another data source), and group them by neighborhood, valuation, neighborhood per-capita income, and other socio-economic factors.</p>\n",
       "<p>The question facing every company today, every startup, every non-profit, every project site that wants to attract a community, is how to use data effectively â not just their own data, but all the data thatâs available and relevant. Using data effectively requires something different from traditional statistics, where actuaries in business suits perform arcane but fairly well-defined kinds of analysis. What differentiates data science from statistics is that data science is a holistic approach. Weâre increasingly finding data in the wild, and data scientists are involved with gathering data, massaging it into a tractable form, making it tell its story, and presenting that story to others.</p>\n",
       "<p>To get a sense for what skills are required, letâs look at the data lifecycle: where it comes from, how you use it, and where it goes.</p>\n",
       "<h2 id=\"data-location\">Where data comes from</h2>\n",
       "<p>Data is everywhere: your government, your web server, your business partners, <a href=\"http://www.nytimes.com/2010/05/02/magazine/02self-measurement-t.html?ref=magazine\">even your body</a>. While we arenât drowning in a sea of data, weâre finding that almost everything can (or has) been instrumented. At OâReilly, we frequently combine publishing industry data from <a href=\"http://en.wikipedia.org/wiki/Nielsen_BookScan\">Nielsen BookScan</a> with our own sales data, publicly available Amazon data, and even job data to see whatâs happening in the publishing industry. Sites like <a href=\"http://infochimps.org/\">Infochimps</a> and <a href=\"http://www.factual.com/\">Factual</a> provide access to many large datasets, including climate data, MySpace activity streams, and game logs from sporting events. Factual enlists users to update and improve its datasets, which cover topics as diverse as endocrinologists to hiking trails.</p>\n",
       "<figure><img alt=\"\" src=\"http://s.radar.oreilly.com/2010/06/01/datascience-56-drive.jpg\"/><figcaption>One of the first commercial disk drives from IBM. It has a 5 MB capacity and itâs stored in a cabinet roughly the size of a luxury refrigerator. In contrast, a 32 GB microSD card measures around 5/8 x 3/8 inch and weighs about 0.5 gram.</figcaption></figure>\n",
       "<p>Much of the data we currently work with is the direct consequence of Web 2.0, and of Mooreâs Law applied to data. The web has people spending more time online, and leaving a trail of data wherever they go. Mobile applications leave an even richer data trail, since many of them are annotated with geolocation, or involve video or audio, all of which can be mined. Point-of-sale devices and frequent-shopperâs cards make it possible to capture all of your retail transactions, not just the ones you make online. All of this data would be useless if we couldnât store it, and thatâs where Mooreâs Law comes in. Since the early â80s, processor speed has increased from <a href=\"http://en.wikipedia.org/wiki/Motorola_68000\">10 MHz</a>    to 3.6 GHz â an increase of 360 (not counting increases in word length and number of cores). But weâve seen much bigger increases in storage capacity, on every level. RAM has moved from $1,000/MB to roughly $25/GB â a price reduction of about 40000, to say nothing of the reduction in size and increase in speed. Hitachi made the <a href=\"http://news.cnet.com/2300-1010_3-6031405-6.html\">first gigabyte disk drives</a> in 1982, weighing in at roughly 250 pounds; now terabyte drives are consumer equipment, and a 32 GB microSD card weighs about half a gram. Whether you look at bits per gram, bits per dollar, or raw capacity, storage has more than kept pace with the increase of CPU speed.</p>\n",
       "<p>The importance of Mooreâs law as applied to data isnât just geek pyrotechnics. Data expands to fill the space you have to store it. The more storage is available, the more data you will find to put into it. The data exhaust you leave behind whenever you surf the web, friend someone on Facebook, or make a purchase in your local supermarket, is all carefully collected and analyzed. Increased storage capacity demands increased sophistication in the analysis and use of that data. Thatâs the foundation of data science.</p>\n",
       "<p>So, how do we make that data useful? The first step of any data analysis project is âdata conditioning,â or getting data into a state where itâs usable. We are seeing more data in formats that are easier to consume: Atom data feeds, web services, microformats, and other newer technologies provide data in formats thatâs directly machine-consumable. But old-style <a href=\"http://en.wikipedia.org/wiki/Data_scraping#Screen_scraping\">screen scraping</a> hasnât died, and isnât going to die. Many sources of âwild dataâ are extremely messy. They arenât well-behaved XML files with all the metadata nicely in place. The foreclosure data used in â<a href=\"http://oreilly.com/catalog/9780596804787 id=hni2\">Data Mashups in R</a>â was posted on a public website by the Philadelphia county sheriffâs office. This data was presented as an HTML file that was probably generated automatically from a spreadsheet. If youâve ever seen the HTML thatâs generated by Excel, you know thatâs going to be fun to process.</p>\n",
       "<p>Data conditioning can involve cleaning up messy HTML with tools like <a href=\"http://www.crummy.com/software/BeautifulSoup/\">Beautiful Soup</a>, natural language processing to parse plain text in English and other languages, or even getting humans to do the dirty work. Youâre likely to be dealing with an array of data sources, all in different forms. It would be nice if there was a standard set of tools to do the job, but there isnât. To do data conditioning, you have to be ready for whatever comes, and be willing to use anything from ancient Unix utilities such as <a href=\"http://oreilly.com/catalog/9780596000707\">awk</a> to XML parsers and machine learning libraries. Scripting languages, such as <a href=\"http://oreilly.com/perl/\">Perl</a> and <a href=\"http://oreilly.com/python/\">Python</a>, are essential.</p>\n",
       "<p>Once youâve parsed the data, you can start thinking about the quality of your data. Data is frequently missing or incongruous. If data is missing, do you simply ignore the missing points? That isnât always possible. If data is incongruous, do you decide that something is wrong with badly behaved data (after all, equipment fails), or that the incongruous data is telling its own story, which may be more interesting? Itâs reported that the discovery of ozone layer depletion was delayed because <a href=\"http://www.nas.nasa.gov/About/Education/Ozone/history.html\">automated data collection tools discarded readings that were too low</a> <sup><a href=\"#footnote-1\">1</a></sup>. In data science, what you have is frequently all youâre going to get. Itâs usually impossible to get âbetterâ data, and you have no alternative but to work with the data at hand.</p>\n",
       "<p>If the problem involves human language, understanding the data adds another dimension to the problem. Roger Magoulas, who runs the data analysis group at OâReilly, was recently searching a database for Apple job listings requiring geolocation skills. While that sounds like a simple task, the trick was disambiguating âAppleâ from many job postings in the growing Apple industry. To do it well you need to understand the grammatical structure of a job posting; you need to be able to parse the English. And that problem is showing up more and more frequently. Try using <a href=\"http://google.com/trends\">Google Trends</a> to figure out whatâs happening with the <a href=\"http://google.com/trends?q=Cassandra\">Cassandra</a> database or the <a href=\"http://google.com/trends?q=Python\">Python</a> language, and youâll get a sense of the problem. Google has indexed many, many websites about large snakes. Disambiguation is never an easy task, but tools like the <a href=\"http://www.nltk.org/\">Natural Language Toolkit</a> library can make it simpler.</p>\n",
       "<p>When natural language processing fails, you can replace artificial intelligence with human intelligence. Thatâs where services like Amazonâs <a href=\"https://www.mturk.com/mturk/welcome id=k3la\">Mechanical Turk</a> come in. If you can split your task up into a large number of subtasks that are easily described, you can use Mechanical Turkâs marketplace for cheap labor. For example, if youâre looking at job listings, and want to know which originated with Apple, you can have real people do the classification for roughly $0.01 each. If you have already reduced the set to 10,000 postings with the word âApple,â paying humans $0.01 to classify them only costs $100.</p>\n",
       "<h2 id=\"data-scale\">Working with data at scale</h2>\n",
       "<p>Weâve all heard a lot about âbig data,â but âbigâ is really a red herring. Oil companies, telecommunications companies, and other data-centric industries have had huge datasets for a long time. And as storage capacity continues to expand, todayâs âbigâ is certainly tomorrowâs âmediumâ and next weekâs âsmall.â The most meaningful definition Iâve heard: <em>âbig dataâ is when the size of the data itself becomes part of the problem</em>. Weâre discussing data problems ranging from gigabytes to petabytes of data. At some point, traditional techniques for working with data run out of steam.</p>\n",
       "<p>What are we trying to do with data thatâs different? According to Jeff Hammerbacher <sup><a href=\"#footnote-2\">2</a></sup> (<a href=\"http://twitter.com/hackingdata\">@hackingdata</a>), weâre trying to build information platforms or dataspaces. Information platforms are similar to traditional data warehouses, but different. They expose rich APIs, and are designed for exploring and understanding the data rather than for traditional analysis and reporting. They accept all data formats, including the most messy, and their schemas evolve as the understanding of the data changes.</p>\n",
       "<p>Most of the organizations that have built data platforms have found it necessary to go beyond the relational database model. Traditional relational database systems stop being effective at this scale. Managing sharding and replication across a horde of database servers is difficult and slow. The need to define a schema in advance conflicts with reality of multiple, unstructured data sources, in which you may not know whatâs important until after youâve analyzed the data. Relational databases are designed for consistency, to support complex transactions that can easily be rolled back if any one of a complex set of operations fails. While rock-solid consistency is crucial to many applications, itâs not really necessary<br/>\n",
       "for the kind of analysis weâre discussing here. Do you really care if you have 1,010 or 1,012 Twitter followers? Precision has an allure, but in most data-driven applications outside of finance, that allure is deceptive. Most data analysis is comparative: if youâre asking whether sales to Northern Europe are increasing faster than sales to Southern Europe, you arenât concerned about the difference between 5.92 percent annual growth and 5.93 percent.</p>\n",
       "<p>To store huge datasets effectively, weâve seen a new breed of databases appear. These are frequently called NoSQL databases, or Non-Relational databases, though neither term is very useful. They group together fundamentally dissimilar products by telling you what they arenât. Many of these databases are the logical descendants of Googleâs <a href=\"http://labs.google.com/papers/bigtable.html\">BigTable</a> and Amazonâs <a href=\"http://www.allthingsdistributed.com/2007/10/amazons_dynamo.html\">Dynamo</a>, and are designed to be distributed across many nodes, to provide âeventual consistencyâ but not absolute consistency, and to have very flexible schema. While there are two dozen or so products available (almost all of them open source), a few leaders have established themselves:</p>\n",
       "<ul>\n",
       "<li><a href=\"http://cassandra.apache.org/\">Cassandra</a>: Developed at Facebook, in production use at Twitter, Rackspace, Reddit, and other large sites. Cassandra is designed for high performance, reliability, and automatic replication. It has a very flexible data model. A new startup, <a href=\"http://www.riptano.com/\">Riptano</a>, provides commercial support.</li>\n",
       "<li><a href=\"http://hadoop.apache.org/hbase/\">HBase</a>: Part of the Apache Hadoop project, and modelled on Googleâs BigTable. Suitable for extremely large databases (billions of rows, millions of columns), distributed across thousands of nodes. Along with Hadoop, commercial support is provided by <a href=\"http://www.cloudera.com/\">Cloudera</a>.</li>\n",
       "</ul>\n",
       "<p>Storing data is only part of building a data platform, though. Data is only useful if you can do something with it, and enormous datasets present computational problems. Google popularized the <a href=\"http://labs.google.com/papers/mapreduce.html\">MapReduce</a> approach, which is basically a divide-and-conquer strategy for distributing an extremely large problem across an extremely large computing cluster. In the âmapâ stage, a programming task is divided into a number of identical subtasks, which are then distributed across many processors; the intermediate results are then combined by a single reduce task. In hindsight, MapReduce seems like an obvious solution to Googleâs biggest problem, creating large searches. Itâs easy to distribute a search across thousands of processors, and then combine the results into a single set of answers. Whatâs less obvious is that MapReduce has proven to be widely applicable to many large data problems, ranging from search to machine learning.</p>\n",
       "<p>The most popular open source implementation of MapReduce is the <a href=\"http://hadoop.apache.org/\">Hadoop project</a>. Yahooâs claim that they had built the <a href=\"http://developer.yahoo.net/blogs/hadoop/2008/02/yahoo-worlds-largest-production-hadoop.html\">worldâs largest production Hadoop application</a>, with 10,000 cores running Linux, brought it onto center stage. Many of the key Hadoop developers have found a home at <a href=\"http://www.cloudera.com/\">Cloudera</a>, which provides commercial support. Amazonâs <a href=\"http://aws.amazon.com/elasticmapreduce/\">Elastic MapReduce</a> makes it much easier to put Hadoop to work without investing in racks of Linux machines, by providing preconfigured Hadoop images for its EC2 clusters. You can allocate and de-allocate processors as needed, paying only for the time you use them.</p>\n",
       "<p><a href=\"http://oreilly.com/catalog/9780596521981\">Hadoop</a> goes far beyond a simple MapReduce implementation (of which there are several); itâs the key component of a data platform. It incorporates <a href=\"http://hadoop.apache.org/hdfs/\">HDFS</a>, a distributed filesystem designed for the performance and reliability requirements of huge datasets; the HBase database; <a href=\"http://hadoop.apache.org/hive/\">Hive</a>, which lets developers explore Hadoop datasets using SQL-like queries; a high-level dataflow language called <a href=\"http://hadoop.apache.org/pig/\">Pig</a>; and other components. If anything can be called a one-stop information platform, Hadoop is it.</p>\n",
       "<p>Hadoop has been instrumental in enabling âagileâ data analysis. In software development, âagile practicesâ are associated with faster product cycles, closer interaction between developers and consumers, and testing. Traditional data analysis has been hampered by extremely long turn-around times. If you start a calculation, it might not finish for hours, or even days. But Hadoop (and particularly Elastic MapReduce) make it easy to build clusters that can perform computations on long datasets quickly. Faster computations make it easier to test different assumptions, different datasets, and different algorithms. Itâs easer to consult with clients to figure out whether youâre asking the right questions, and itâs possible to pursue intriguing possibilities that youâd otherwise have to drop for lack of time.</p>\n",
       "<p>Hadoop is essentially a batch system, but <a href=\"http://code.google.com/p/hop/\">Hadoop Online Prototype (HOP)</a> is an experimental project that enables stream processing. Hadoop processes data as it arrives, and delivers intermediate results in (near) real-time. Near real-time data analysis enables features like <a href=\"http://search.twitter.com/\">trending topics</a> on sites like <a href=\"http://twitter.com/\">Twitter</a>. These features only require soft real-time; reports on trending topics donât require millisecond accuracy. As with the number of followers on Twitter, a âtrending topicsâ report only needs to be current to within five minutes â or even an hour. According to Hilary Mason (<a href=\"http://twitter.com/hmason\">@hmason</a>), data scientist at <a href=\"http://bit.ly/\">bit.ly</a>, itâs possible to precompute much of the calculation, then use one of the experiments in real-time MapReduce to get presentable results.</p>\n",
       "<p>Machine learning is another essential tool for the data scientist. We now expect web and mobile applications to incorporate recommendation engines, and building a recommendation engine is a quintessential artificial intelligence problem. You donât have to look at many modern web applications to see classification, error detection, image matching (behind <a href=\"http://www.google.com/mobile/goggles/\">Google Goggles</a> and <a href=\"http://www.snaptell.com/\">SnapTell</a>) and even face detection â an ill-advised mobile application lets you take someoneâs picture with a cell phone, and look up that personâs identity using photos available online. <a href=\"http://www.stanford.edu/class/cs229/\">Andrew Ngâs Machine Learning course</a> is one of the most popular courses in computer science at Stanford, with hundreds of students (<a href=\"http://www.youtube.com/watch?v=UzxYlbK2c7E id=j0ha\">this video is highly recommended</a>).</p>\n",
       "<p>There are many libraries available for machine learning: <a href=\"http://pybrain.org/\">PyBrain</a> in Python, <a href=\"http://elefant.developer.nicta.com.au/\">Elefant</a>, <a href=\"http://www.cs.waikato.ac.nz/ml/weka/\">Weka</a> in Java, and <a href=\"http://lucene.apache.org/mahout/\">Mahout</a> (coupled to Hadoop). Google has just announced their <a href=\"http://code.google.com/apis/predict/\">Prediction API</a>, which exposes their machine learning algorithms for public use via a RESTful interface. For computer vision, the <a href=\"http://opencv.willowgarage.com/wiki/\">OpenCV</a> library is a de-facto standard.</p>\n",
       "<p><a href=\"https://www.mturk.com/mturk/welcome id=k3la\">Mechanical Turk</a> is also an important part of the toolbox. Machine learning almost always requires a âtraining set,â or a significant body of known data with which to develop and tune the application. The Turk is an excellent way to develop training sets. Once youâve collected your training data (perhaps a large collection of public photos from Twitter), you can have humans classify them inexpensively â possibly sorting them into categories, possibly drawing circles around faces, cars, or whatever interests you. Itâs an excellent way to classify a few thousand data points at a cost of a few cents each. Even a relatively large job only costs a few hundred dollars.</p>\n",
       "<p>While I havenât stressed traditional statistics, building statistical models plays an important role in any data analysis. According to <a href=\"http://www.dataspora.com/\">Mike Driscoll</a> (<a href=\"http://twitter.com/dataspora\">@dataspora</a>), statistics is the âgrammar of data science.â It is crucial to âmaking data speak coherently.â Weâve all heard the joke that eating pickles causes death, because everyone who dies has eaten pickles. That joke doesnât work if you understand what correlation means. More to the point, itâs easy to notice that one advertisement for <em><a href=\"http://oreilly.com/catalog/9780596801717/\">R in a Nutshell</a></em> generated 2 percent more conversions than another.</p>\n",
       "<p>But it takes statistics to know whether this difference is significant, or just a random fluctuation. Data science isnât just about the existence of data, or making guesses about what that data might mean; itâs about testing hypotheses and making sure that the conclusions youâre drawing from the data are valid. Statistics plays a role in everything from traditional business intelligence (BI) to understanding how Googleâs ad auctions work. Statistics has become a basic skill. It isnât superseded by newer techniques from machine learning and other disciplines; it complements them.</p>\n",
       "<p>While there are many commercial statistical packages, the open source <a href=\"http://www.r-project.org/\">R language</a> â and its comprehensive package library, <a href=\"http://cran.r-project.org/\">CRAN</a> â is an essential tool. Although R is an odd and quirky language, particularly to someone with a background in computer science, it comes close to providing âone stop shoppingâ for most statistical work. It has excellent graphics facilities; CRAN includes parsers for many kinds of data; and newer extensions extend R into distributed computing. If thereâs a single tool that provides an end-to-end solution for statistics work, R is it.</p>\n",
       "<h2 id=\"data-story\">Making data tell its story</h2>\n",
       "<p>A picture may or may not be worth a thousand words, but a picture is certainly worth a thousand numbers. The problem with most data analysis algorithms is that they generate a set of numbers. To understand what the numbers mean, the stories they are really telling, you need to generate a graph. Edward Tufteâs <a href=\"http://www.amazon.com/Visual-Display-Quantitative-Information-2nd/dp/0961392142/\">Visual Display of Quantitative Information</a> is the classic for data visualization, and a foundational text for anyone practicing data science. But thatâs not really what concerns us here. Visualization is crucial to each stage of the data scientist. According to Martin Wattenberg (<a href=\"http://twitter.com/wattenberg\">@wattenberg</a>, founder of <a>Flowing Media)</a>, visualization is key to data conditioning: if you want to find out just how bad your data is, try plotting it. Visualization is also frequently the first step in analysis. Hilary Mason says that when she gets a new data set, she starts by making a dozen or more scatter plots, trying to get a sense of what might be interesting. Once youâve gotten some hints at what the data might be saying, you can follow it up with more detailed analysis.</p>\n",
       "<p>There are many packages for plotting and presenting data. <a href=\"http://www.gnuplot.info/\">GnuPlot</a> is very effective; R incorporates a fairly comprehensive graphics package; Casey Reasâ and Ben Fryâs <a href=\"http://processing.org/\">Processing</a>    is the state of the art, particularly if you need to create animations that show how things change over time. At IBMâs <a href=\"http://manyeyes.alphaworks.ibm.com/manyeyes/\">Many Eyes</a>, many of the visualizations are full-fledged interactive applications.</p>\n",
       "<p>Nathan Yauâs <a href=\"http://flowingdata.com/\">FlowingData</a> blog is a great place to look for creative visualizations. One of my favorites is this animation of the <a href=\"http://flowingdata.com/2010/04/07/watching-the-growth-of-walmart-now-with-100-more-sams-club/\">growth of Walmart</a> over time. And this is one place where âartâ comes in: not just the aesthetics of the visualization itself, but how you understand it. Does it look like the spread of cancer throughout a body? Or the spread of a flu virus through a population?</p>\n",
       "<p>Making data tell its story isnât just a matter of presenting results; it involves making connections, then going back to other data sources to verify them. Does a successful retail chain spread like an epidemic, and if so, does that give us<br/>\n",
       "new insights into how economies work? Thatâs not a question we could even have asked a few years ago. There was insufficient computing power, the data was all locked up in proprietary sources, and the tools for working with the data were insufficient.</p>\n",
       "<p>Itâs the kind of question we now ask routinely.</p>\n",
       "<h2 id=\"data-scientists\">Data scientists</h2>\n",
       "<p>Data science requires skills ranging from traditional computer science to mathematics to art. Describing the data science group he put together at Facebook (possibly the first data science group at a consumer-oriented web property), Jeff Hammerbacher said:</p>\n",
       "<blockquote><p>â¦ on any given day, a team member could author a multistage processing pipeline in Python, design a hypothesis test, perform a regression analysis over data samples with R, design and implement an algorithm for some data-intensive product or service in Hadoop, or communicate the results of our analyses to other members of the organization <sup><a href=\"#footnote-3\">3</a></sup></p></blockquote>\n",
       "<p>Where do you find the people this versatile? According to DJ Patil, chief scientist at <a href=\"http://www.linkedin.com/\">LinkedIn</a> (<a href=\"http://twitter.com/dpatil\">@dpatil</a>), the best data scientists tend to be âhard scientists,â particularly physicists, rather than computer science majors. Physicists have a strong mathematical background, computing skills, and come from a discipline in which survival depends on getting the most from the data. They have to think about the big picture, the big problem. When youâve just spent a lot of grant money generating data, you canât just throw the data out if it isnât as clean as youâd like. You have to make it tell its story. You need some creativity for when the story the data is telling isnât what you think itâs telling.</p>\n",
       "<p>Scientists also know how to break large problems up into smaller problems. Patil described the process of creating the group recommendation feature at LinkedIn. It would have been easy to turn this into a high-ceremony development project that would take thousands of hours of developer time, plus thousands of hours of computing time to do massive correlations across LinkedInâs membership. But the process worked quite differently: it started out with a relatively small, simple program that looked at membersâ profiles and made recommendations accordingly. Asking things like, did you go to Cornell? Then you might like to join the Cornell Alumni group. It then branched out incrementally. In addition to looking at profiles, LinkedInâs data scientists started looking at events that members attended. Then at books members had in their libraries. The result was a valuable data product that analyzed a huge database â but it was never conceived as such. It started small, and added value iteratively. It was an agile, flexible process that built toward its goal incrementally, rather than tackling a huge mountain of data all at once.</p>\n",
       "<p>This is the heart of what Patil calls âdata jiujitsuâ â using smaller auxiliary problems to solve a large, difficult problem that appears intractable. CDDB is a great example of data jiujitsu: identifying music by analyzing an audio<br/>\n",
       "stream directly is a very difficult problem (though not unsolvable â see <a href=\"http://www.midomi.com/\">midomi</a>, for example). But the CDDB staff used data creatively to solve a much more tractable problem that gave them the same result. Computing a signature based on track lengths, and then looking up that signature in a database, is trivially simple.</p>\n",
       "<p><!-- hiring trends sidebar --></p>\n",
       "<figure><img alt=\"\" src=\"http://s.radar.oreilly.com/2010/06/01/datascience-jobs.png\"/><figcaption>Itâs not easy to get a handle on jobs in data science. However, data from <a href=\"http://radar.oreilly.com/research/\">OâReilly Research</a> shows a steady year-over-year increase in Hadoop and Cassandra job listings, which are good proxies for the âdata scienceâ market as a whole. This graph shows the increase in Cassandra jobs, and the companies listing Cassandra positions, over time.</figcaption></figure>\n",
       "<p>Entrepreneurship is another piece of the puzzle. Patilâs first flippant answer to âwhat kind of person are you looking for when you hire a data scientist?â was âsomeone you would start a company with.â Thatâs an important insight: weâre entering the era of products that are built on data. We donât yet know what those products are, but we do know that the winners will be the people, and the companies, that find those products. Hilary Mason came to the same conclusion. Her job as scientist at bit.ly is really to investigate the data that bit.ly is generating, and find out how to build interesting products from it. No one in the nascent data industry is trying to build the 2012 Nissan Stanza or Office 2015; theyâre all trying to find new products. In addition to being physicists, mathematicians, programmers, and artists, theyâre entrepreneurs.</p>\n",
       "<p>Data scientists combine entrepreneurship with patience, the willingness to build data products incrementally, the ability to explore, and the ability to iterate over a solution. They are inherently interdiscplinary. They can tackle all aspects of a problem, from initial data collection and data conditioning to drawing conclusions. They can think outside the box to come up with new ways to view the problem, or to work with very broadly defined problems: âhereâs a lot of data, what can you make from it?â</p>\n",
       "<p>The future belongs to the companies who figure out how to collect and use data successfully. Google, Amazon, Facebook, and LinkedIn have all tapped into their datastreams and made that the core of their success. They were the vanguard, but newer companies like bit.ly are following their path. Whether itâs mining your personal biology, building maps from the shared experience of millions of travellers, or studying the URLs that people pass to others, the next generation of successful businesses will be built around data. <a href=\"http://www.mckinseyquarterly.com/Hal_Varian_on_how_the_Web_challenges_managers_2286\">The part of Hal Varianâs quote that nobody remembers says it all</a>:</p>\n",
       "<blockquote><p><strong>The ability to take data â to be able to understand it, to process it, to extract value from it, to visualize it, to communicate it â thatâs going to be a hugely important skill in the next decades.</strong></p></blockquote>\n",
       "<p>Data is indeed the new Intel Inside.</p>\n",
       "<p><sup>1</sup> The NASA article denies this, but also says that in 1984, they decided that the low values (whch went back to the 70s) were âreal.â Whether humans or software decided to ignore anomalous data, it appears that data was ignored.</p>\n",
       "<p><sup>2 </sup> âInformation Platforms as Dataspaces,â by Jeff Hammerbacher (in <em><a>Beautiful Data</a></em>)</p>\n",
       "<p><sup>3 </sup> âInformation Platforms as Dataspaces,â by Jeff Hammerbacher (in <em><a>Beautiful Data</a></em>)</p>\n",
       "\n",
       "                          </div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = soup.find(\"div\", \"main-post-radar-content\")   # find article-body div\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is far from clean as most data you will get so lets do some basic cleaning. First we will clean some of the apostrophes that are character \"â\" and replace them with a normal apostrophes with a function calles fix_unicode. Next we will want to create a sequence (list) of words and use the \".\" as a way of marking where each sentence ends.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_apostrophes(text: str) -> str:\n",
    "    return text.replace(\"â\", \"'\")\n",
    "\n",
    "regex = r\"[\\w']+|[\\.]\"                      \n",
    "document = []\n",
    "\n",
    "for paragraph in content(\"p\"):\n",
    "    words = re.findall(regex, fix_apostrophes(paragraph.text))\n",
    "    document.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We'\",\n",
       " 've',\n",
       " 'all',\n",
       " 'heard',\n",
       " 'it',\n",
       " 'according',\n",
       " 'to',\n",
       " 'Hal',\n",
       " 'Varian',\n",
       " 'statistics',\n",
       " 'is',\n",
       " 'the',\n",
       " 'next',\n",
       " 'sexy',\n",
       " 'job',\n",
       " '.',\n",
       " 'Five',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'in',\n",
       " 'What',\n",
       " 'is',\n",
       " 'Web',\n",
       " '2',\n",
       " '.',\n",
       " '0',\n",
       " 'Tim',\n",
       " \"O'\",\n",
       " 'Reilly',\n",
       " 'said',\n",
       " 'that',\n",
       " \"'\",\n",
       " 'data',\n",
       " 'is',\n",
       " 'the',\n",
       " 'next',\n",
       " 'Intel',\n",
       " 'Inside',\n",
       " '.',\n",
       " \"'\",\n",
       " 'But',\n",
       " 'what',\n",
       " 'does',\n",
       " 'that',\n",
       " 'statement',\n",
       " 'mean',\n",
       " 'Why',\n",
       " 'do',\n",
       " 'we',\n",
       " 'suddenly',\n",
       " 'care',\n",
       " 'about',\n",
       " 'statistics',\n",
       " 'and',\n",
       " 'about',\n",
       " 'data',\n",
       " 'In',\n",
       " 'this',\n",
       " 'post',\n",
       " 'I',\n",
       " 'examine',\n",
       " 'the',\n",
       " 'many',\n",
       " 'sides',\n",
       " 'of',\n",
       " 'data',\n",
       " 'science',\n",
       " \"'\",\n",
       " 'the',\n",
       " 'technologies',\n",
       " 'the',\n",
       " 'companies',\n",
       " 'and',\n",
       " 'the',\n",
       " 'unique',\n",
       " 'skill',\n",
       " 'sets',\n",
       " '.',\n",
       " 'Join',\n",
       " 'the',\n",
       " \"O'Reilly\",\n",
       " 'online',\n",
       " 'learning',\n",
       " 'platform',\n",
       " '.',\n",
       " 'Get',\n",
       " 'a',\n",
       " 'free',\n",
       " 'trial',\n",
       " 'today',\n",
       " 'and',\n",
       " 'find',\n",
       " 'answers',\n",
       " 'on',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'or',\n",
       " 'master',\n",
       " 'something',\n",
       " 'new',\n",
       " 'and',\n",
       " 'useful',\n",
       " '.',\n",
       " 'The',\n",
       " 'web',\n",
       " 'is',\n",
       " 'full',\n",
       " 'of',\n",
       " \"'\",\n",
       " 'data',\n",
       " 'driven',\n",
       " 'apps',\n",
       " '.',\n",
       " \"'\",\n",
       " 'Almost',\n",
       " 'any',\n",
       " 'e',\n",
       " 'commerce',\n",
       " 'application',\n",
       " 'is',\n",
       " 'a',\n",
       " 'data',\n",
       " 'driven',\n",
       " 'application',\n",
       " '.',\n",
       " \"There'\",\n",
       " 's',\n",
       " 'a',\n",
       " 'database',\n",
       " 'behind',\n",
       " 'a',\n",
       " 'web',\n",
       " 'front',\n",
       " 'end',\n",
       " 'and',\n",
       " 'middleware',\n",
       " 'that',\n",
       " 'talks',\n",
       " 'to',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'other',\n",
       " 'databases',\n",
       " 'and',\n",
       " 'data',\n",
       " 'services',\n",
       " 'credit',\n",
       " 'card',\n",
       " 'processing',\n",
       " 'companies',\n",
       " 'banks',\n",
       " 'and',\n",
       " 'so',\n",
       " 'on',\n",
       " '.',\n",
       " 'But',\n",
       " 'merely',\n",
       " 'using',\n",
       " 'data',\n",
       " \"isn'\",\n",
       " 't',\n",
       " 'really',\n",
       " 'what',\n",
       " 'we',\n",
       " 'mean',\n",
       " 'by',\n",
       " \"'\",\n",
       " 'data',\n",
       " 'science',\n",
       " '.',\n",
       " \"'\",\n",
       " 'A',\n",
       " 'data',\n",
       " 'application',\n",
       " 'acquires',\n",
       " 'its',\n",
       " 'value',\n",
       " 'from',\n",
       " 'the',\n",
       " 'data',\n",
       " 'itself',\n",
       " 'and',\n",
       " 'creates',\n",
       " 'more',\n",
       " 'data',\n",
       " 'as',\n",
       " 'a',\n",
       " 'result',\n",
       " '.',\n",
       " \"It'\",\n",
       " 's',\n",
       " 'not',\n",
       " 'just',\n",
       " 'an',\n",
       " 'application',\n",
       " 'with',\n",
       " 'data',\n",
       " \"it'\",\n",
       " 's',\n",
       " 'a',\n",
       " 'data',\n",
       " 'product',\n",
       " '.',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'enables',\n",
       " 'the',\n",
       " 'creation',\n",
       " 'of',\n",
       " 'data',\n",
       " 'products',\n",
       " '.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earlier',\n",
       " 'data',\n",
       " 'products',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Web',\n",
       " 'was',\n",
       " 'the',\n",
       " 'CDDB',\n",
       " 'database',\n",
       " '.',\n",
       " 'The',\n",
       " 'developers',\n",
       " 'of',\n",
       " 'CDDB',\n",
       " 'realized',\n",
       " 'that',\n",
       " 'any',\n",
       " 'CD',\n",
       " 'had',\n",
       " 'a',\n",
       " 'unique',\n",
       " 'signature',\n",
       " 'based',\n",
       " 'on',\n",
       " 'the',\n",
       " 'exact',\n",
       " 'length',\n",
       " 'in',\n",
       " 'samples',\n",
       " 'of',\n",
       " 'each',\n",
       " 'track',\n",
       " 'on',\n",
       " 'the',\n",
       " 'CD',\n",
       " '.',\n",
       " 'Gracenote',\n",
       " 'built',\n",
       " 'a',\n",
       " 'database',\n",
       " 'of',\n",
       " 'track',\n",
       " 'lengths',\n",
       " 'and',\n",
       " 'coupled',\n",
       " 'it',\n",
       " 'to',\n",
       " 'a',\n",
       " 'database',\n",
       " 'of',\n",
       " 'album',\n",
       " 'metadata',\n",
       " 'track',\n",
       " 'titles',\n",
       " 'artists',\n",
       " 'album',\n",
       " 'titles',\n",
       " '.',\n",
       " 'If',\n",
       " \"you'\",\n",
       " 've',\n",
       " 'ever',\n",
       " 'used',\n",
       " 'iTunes',\n",
       " 'to',\n",
       " 'rip',\n",
       " 'a',\n",
       " 'CD',\n",
       " \"you'\",\n",
       " 've',\n",
       " 'taken',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'this',\n",
       " 'database',\n",
       " '.',\n",
       " 'Before',\n",
       " 'it',\n",
       " 'does',\n",
       " 'anything',\n",
       " 'else',\n",
       " 'iTunes',\n",
       " 'reads',\n",
       " 'the',\n",
       " 'length',\n",
       " 'of',\n",
       " 'every',\n",
       " 'track',\n",
       " 'sends',\n",
       " 'it',\n",
       " 'to',\n",
       " 'CDDB',\n",
       " 'and',\n",
       " 'gets',\n",
       " 'back',\n",
       " 'the',\n",
       " 'track',\n",
       " 'titles',\n",
       " '.',\n",
       " 'If',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'CD',\n",
       " \"that'\",\n",
       " 's',\n",
       " 'not',\n",
       " 'in',\n",
       " 'the',\n",
       " 'database',\n",
       " 'including',\n",
       " 'a',\n",
       " 'CD',\n",
       " \"you'\",\n",
       " 've',\n",
       " 'made',\n",
       " 'yourself',\n",
       " 'you',\n",
       " 'can',\n",
       " 'create',\n",
       " 'an',\n",
       " 'entry',\n",
       " 'for',\n",
       " 'an',\n",
       " 'unknown',\n",
       " 'album',\n",
       " '.',\n",
       " 'While',\n",
       " 'this',\n",
       " 'sounds',\n",
       " 'simple',\n",
       " 'enough',\n",
       " \"it'\",\n",
       " 's',\n",
       " 'revolutionary',\n",
       " 'CDDB',\n",
       " 'views',\n",
       " 'music',\n",
       " 'as',\n",
       " 'data',\n",
       " 'not',\n",
       " 'as',\n",
       " 'audio',\n",
       " 'and',\n",
       " 'creates',\n",
       " 'new',\n",
       " 'value',\n",
       " 'in',\n",
       " 'doing',\n",
       " 'so',\n",
       " '.',\n",
       " 'Their',\n",
       " 'business',\n",
       " 'is',\n",
       " 'fundamentally',\n",
       " 'different',\n",
       " 'from',\n",
       " 'selling',\n",
       " 'music',\n",
       " 'sharing',\n",
       " 'music',\n",
       " 'or',\n",
       " 'analyzing',\n",
       " 'musical',\n",
       " 'tastes',\n",
       " 'though',\n",
       " 'these',\n",
       " 'can',\n",
       " 'also',\n",
       " 'be',\n",
       " \"'\",\n",
       " 'data',\n",
       " \"products'\",\n",
       " '.',\n",
       " 'CDDB',\n",
       " 'arises',\n",
       " 'entirely',\n",
       " 'from',\n",
       " 'viewing',\n",
       " 'a',\n",
       " 'musical',\n",
       " 'problem',\n",
       " 'as',\n",
       " 'a',\n",
       " 'data',\n",
       " 'problem',\n",
       " '.',\n",
       " 'Google',\n",
       " 'is',\n",
       " 'a',\n",
       " 'master',\n",
       " 'at',\n",
       " 'creating',\n",
       " 'data',\n",
       " 'products',\n",
       " '.',\n",
       " \"Here'\",\n",
       " 's',\n",
       " 'a',\n",
       " 'few',\n",
       " 'examples',\n",
       " 'Google',\n",
       " \"isn'\",\n",
       " 't',\n",
       " 'the',\n",
       " 'only',\n",
       " 'company',\n",
       " 'that',\n",
       " 'knows',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'data',\n",
       " '.',\n",
       " 'Facebook',\n",
       " 'and',\n",
       " 'LinkedIn',\n",
       " 'use',\n",
       " 'patterns',\n",
       " 'of',\n",
       " 'friendship',\n",
       " 'relationships',\n",
       " 'to',\n",
       " 'suggest',\n",
       " 'other',\n",
       " 'people',\n",
       " 'you',\n",
       " 'may',\n",
       " 'know',\n",
       " 'or',\n",
       " 'should',\n",
       " 'know',\n",
       " 'with',\n",
       " 'sometimes',\n",
       " 'frightening',\n",
       " 'accuracy',\n",
       " '.',\n",
       " 'Amazon',\n",
       " 'saves',\n",
       " 'your',\n",
       " 'searches',\n",
       " 'correlates',\n",
       " 'what',\n",
       " 'you',\n",
       " 'search',\n",
       " 'for',\n",
       " 'with',\n",
       " 'what',\n",
       " 'other',\n",
       " 'users',\n",
       " 'search',\n",
       " 'for',\n",
       " 'and',\n",
       " 'uses',\n",
       " 'it',\n",
       " 'to',\n",
       " 'create',\n",
       " 'surprisingly',\n",
       " 'appropriate',\n",
       " 'recommendations',\n",
       " '.',\n",
       " 'These',\n",
       " 'recommendations',\n",
       " 'are',\n",
       " \"'\",\n",
       " 'data',\n",
       " \"products'\",\n",
       " 'that',\n",
       " 'help',\n",
       " 'to',\n",
       " 'drive',\n",
       " \"Amazon'\",\n",
       " 's',\n",
       " 'more',\n",
       " 'traditional',\n",
       " 'retail',\n",
       " 'business',\n",
       " '.',\n",
       " 'They',\n",
       " 'come',\n",
       " 'about',\n",
       " 'because',\n",
       " 'Amazon',\n",
       " 'understands',\n",
       " 'that',\n",
       " 'a',\n",
       " 'book',\n",
       " \"isn'\",\n",
       " 't',\n",
       " 'just',\n",
       " 'a',\n",
       " 'book',\n",
       " 'a',\n",
       " 'camera',\n",
       " \"isn'\",\n",
       " 't',\n",
       " 'just',\n",
       " 'a',\n",
       " 'camera',\n",
       " 'and',\n",
       " 'a',\n",
       " 'customer',\n",
       " \"isn'\",\n",
       " 't',\n",
       " 'ust',\n",
       " 'a',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'generate',\n",
       " 'a',\n",
       " 'trail',\n",
       " 'of',\n",
       " \"'\",\n",
       " 'data',\n",
       " \"exhaust'\",\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'mined',\n",
       " 'and',\n",
       " 'put',\n",
       " 'to',\n",
       " 'use',\n",
       " 'and',\n",
       " 'a',\n",
       " 'camera',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cloud',\n",
       " 'of',\n",
       " 'data',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'correlated',\n",
       " 'with',\n",
       " 'the',\n",
       " \"customers'\",\n",
       " 'behavior',\n",
       " 'the',\n",
       " 'data',\n",
       " 'they',\n",
       " 'leave',\n",
       " 'every',\n",
       " 'time',\n",
       " 'they',\n",
       " 'visit',\n",
       " 'the',\n",
       " 'site',\n",
       " '.',\n",
       " 'The',\n",
       " 'thread',\n",
       " 'that',\n",
       " 'ties',\n",
       " 'most',\n",
       " 'of',\n",
       " 'these',\n",
       " 'applications',\n",
       " 'together',\n",
       " 'is',\n",
       " 'that',\n",
       " 'data',\n",
       " 'collected',\n",
       " 'from',\n",
       " 'users',\n",
       " 'provides',\n",
       " 'added',\n",
       " 'value',\n",
       " '.',\n",
       " 'Whether',\n",
       " 'that',\n",
       " 'data',\n",
       " 'is',\n",
       " 'search',\n",
       " 'terms',\n",
       " 'voice',\n",
       " 'samples',\n",
       " 'or',\n",
       " 'product',\n",
       " 'reviews',\n",
       " 'the',\n",
       " 'users',\n",
       " 'are',\n",
       " 'in',\n",
       " 'a',\n",
       " 'feedback',\n",
       " 'loop',\n",
       " 'in',\n",
       " 'which',\n",
       " 'they',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'the',\n",
       " 'products',\n",
       " 'they',\n",
       " 'use',\n",
       " '.',\n",
       " \"That'\",\n",
       " 's',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'data',\n",
       " 'science',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'last',\n",
       " 'few',\n",
       " 'years',\n",
       " 'there',\n",
       " 'has',\n",
       " 'been',\n",
       " 'an',\n",
       " 'explosion',\n",
       " 'in',\n",
       " 'the',\n",
       " 'amount',\n",
       " 'of',\n",
       " 'data',\n",
       " \"that'\",\n",
       " 's',\n",
       " 'available',\n",
       " '.',\n",
       " 'Whether',\n",
       " \"we'\",\n",
       " 're',\n",
       " 'talking',\n",
       " 'about',\n",
       " 'web',\n",
       " 'server',\n",
       " 'logs',\n",
       " 'tweet',\n",
       " 'streams',\n",
       " 'online',\n",
       " 'transaction',\n",
       " 'records',\n",
       " \"'\",\n",
       " 'citizen',\n",
       " 'science',\n",
       " \"'\",\n",
       " 'data',\n",
       " 'from',\n",
       " 'sensors',\n",
       " 'government',\n",
       " 'data',\n",
       " 'or',\n",
       " 'some',\n",
       " 'other',\n",
       " 'source',\n",
       " 'the',\n",
       " 'problem',\n",
       " \"isn'\",\n",
       " 't',\n",
       " 'finding',\n",
       " 'data',\n",
       " \"it'\",\n",
       " 's',\n",
       " 'figuring',\n",
       " 'out',\n",
       " 'what',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'it',\n",
       " '.',\n",
       " 'And',\n",
       " \"it'\",\n",
       " 's',\n",
       " 'not',\n",
       " 'just',\n",
       " 'companies',\n",
       " 'using',\n",
       " 'their',\n",
       " 'own',\n",
       " 'data',\n",
       " 'or',\n",
       " 'the',\n",
       " 'data',\n",
       " 'contributed',\n",
       " 'by',\n",
       " 'their',\n",
       " 'users',\n",
       " '.',\n",
       " \"It'\",\n",
       " 's',\n",
       " 'increasingly',\n",
       " 'common',\n",
       " 'to',\n",
       " 'mashup',\n",
       " 'data',\n",
       " 'from',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'sources',\n",
       " '.',\n",
       " \"'\",\n",
       " 'Data',\n",
       " 'Mashups',\n",
       " 'in',\n",
       " \"R'\",\n",
       " 'analyzes',\n",
       " 'mortgage',\n",
       " 'foreclosures',\n",
       " 'in',\n",
       " 'Philadelphia',\n",
       " 'County',\n",
       " 'by',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'public',\n",
       " 'report',\n",
       " 'from',\n",
       " 'the',\n",
       " 'county',\n",
       " \"sheriff'\",\n",
       " 's',\n",
       " 'office',\n",
       " 'extracting',\n",
       " 'addresses',\n",
       " 'and',\n",
       " 'using',\n",
       " 'Yahoo',\n",
       " 'to',\n",
       " 'convert',\n",
       " 'the',\n",
       " 'addresses',\n",
       " 'to',\n",
       " 'latitude',\n",
       " 'and',\n",
       " 'longitude',\n",
       " 'then',\n",
       " 'using',\n",
       " 'the',\n",
       " 'geographical',\n",
       " 'data',\n",
       " 'to',\n",
       " 'place',\n",
       " 'the',\n",
       " 'foreclosures',\n",
       " 'on',\n",
       " 'a',\n",
       " 'map',\n",
       " 'another',\n",
       " 'data',\n",
       " 'source',\n",
       " 'and',\n",
       " 'group',\n",
       " 'them',\n",
       " 'by',\n",
       " 'neighborhood',\n",
       " 'valuation',\n",
       " 'neighborhood',\n",
       " 'per',\n",
       " 'capita',\n",
       " 'income',\n",
       " 'and',\n",
       " 'other',\n",
       " 'socio',\n",
       " 'economic',\n",
       " 'factors',\n",
       " '.',\n",
       " 'The',\n",
       " 'question',\n",
       " 'facing',\n",
       " 'every',\n",
       " 'company',\n",
       " 'today',\n",
       " 'every',\n",
       " 'startup',\n",
       " 'every',\n",
       " 'non',\n",
       " 'profit',\n",
       " 'every',\n",
       " 'project',\n",
       " 'site',\n",
       " 'that',\n",
       " 'wants',\n",
       " 'to',\n",
       " 'attract',\n",
       " 'a',\n",
       " 'community',\n",
       " 'is',\n",
       " 'how',\n",
       " 'to',\n",
       " 'use',\n",
       " 'data',\n",
       " 'effectively',\n",
       " \"'\",\n",
       " 'not',\n",
       " 'just',\n",
       " 'their',\n",
       " 'own',\n",
       " 'data',\n",
       " 'but',\n",
       " 'all',\n",
       " 'the',\n",
       " 'data',\n",
       " \"that'\",\n",
       " 's',\n",
       " 'available',\n",
       " 'and',\n",
       " 'relevant',\n",
       " '.',\n",
       " 'Using',\n",
       " 'data',\n",
       " 'effectively',\n",
       " 'requires',\n",
       " 'something',\n",
       " 'different',\n",
       " 'from',\n",
       " 'traditional',\n",
       " 'statistics',\n",
       " 'where',\n",
       " 'actuaries',\n",
       " 'in',\n",
       " 'business',\n",
       " 'suits',\n",
       " 'perform',\n",
       " 'arcane',\n",
       " 'but',\n",
       " 'fairly',\n",
       " 'well',\n",
       " 'defined',\n",
       " 'kinds',\n",
       " 'of',\n",
       " 'analysis',\n",
       " '.',\n",
       " 'What',\n",
       " 'differentiates',\n",
       " 'data',\n",
       " 'science',\n",
       " 'from',\n",
       " 'statistics',\n",
       " 'is',\n",
       " 'that',\n",
       " 'data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'a',\n",
       " 'holistic',\n",
       " 'approach',\n",
       " '.',\n",
       " \"We'\",\n",
       " 're',\n",
       " 'increasingly',\n",
       " 'finding',\n",
       " 'data',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wild',\n",
       " 'and',\n",
       " 'data',\n",
       " 'scientists',\n",
       " 'are',\n",
       " 'involved',\n",
       " 'with',\n",
       " 'gathering',\n",
       " 'data',\n",
       " 'massaging',\n",
       " 'it',\n",
       " 'into',\n",
       " 'a',\n",
       " 'tractable',\n",
       " 'form',\n",
       " 'making',\n",
       " 'it',\n",
       " 'tell',\n",
       " 'its',\n",
       " 'story',\n",
       " 'and',\n",
       " 'presenting',\n",
       " 'that',\n",
       " 'story',\n",
       " 'to',\n",
       " 'others',\n",
       " '.',\n",
       " 'To',\n",
       " 'get',\n",
       " 'a',\n",
       " 'sense',\n",
       " 'for',\n",
       " 'what',\n",
       " 'skills',\n",
       " 'are',\n",
       " 'required',\n",
       " \"let'\",\n",
       " 's',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'data',\n",
       " 'lifecycle',\n",
       " 'where',\n",
       " 'it',\n",
       " 'comes',\n",
       " 'from',\n",
       " 'how',\n",
       " 'you',\n",
       " 'use',\n",
       " 'it',\n",
       " 'and',\n",
       " 'where',\n",
       " 'it',\n",
       " 'goes',\n",
       " '.',\n",
       " 'Data',\n",
       " 'is',\n",
       " 'everywhere',\n",
       " 'your',\n",
       " 'government',\n",
       " 'your',\n",
       " 'web',\n",
       " 'server',\n",
       " 'your',\n",
       " 'business',\n",
       " 'partners',\n",
       " 'even',\n",
       " 'your',\n",
       " 'body',\n",
       " '.',\n",
       " 'While',\n",
       " 'we',\n",
       " \"aren'\",\n",
       " 't',\n",
       " 'drowning',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sea',\n",
       " 'of',\n",
       " 'data',\n",
       " \"we'\",\n",
       " 're',\n",
       " 'finding',\n",
       " 'that',\n",
       " 'almost',\n",
       " 'everything',\n",
       " 'can',\n",
       " 'or',\n",
       " 'has',\n",
       " 'been',\n",
       " 'instrumented',\n",
       " '.',\n",
       " 'At',\n",
       " \"O'\",\n",
       " 'Reilly',\n",
       " 'we',\n",
       " 'frequently',\n",
       " 'combine',\n",
       " 'publishing',\n",
       " 'industry',\n",
       " 'data',\n",
       " 'from',\n",
       " 'Nielsen',\n",
       " 'BookScan',\n",
       " 'with',\n",
       " 'our',\n",
       " 'own',\n",
       " 'sales',\n",
       " 'data',\n",
       " 'publicly',\n",
       " 'available',\n",
       " 'Amazon',\n",
       " 'data',\n",
       " 'and',\n",
       " 'even',\n",
       " 'job',\n",
       " 'data',\n",
       " 'to',\n",
       " 'see',\n",
       " \"what'\",\n",
       " 's',\n",
       " 'happening',\n",
       " 'in',\n",
       " 'the',\n",
       " 'publishing',\n",
       " 'industry',\n",
       " '.',\n",
       " 'Sites',\n",
       " 'like',\n",
       " 'Infochimps',\n",
       " 'and',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a bigram model we can, given some starting word, can randomly choose one of one of the words that follow it in the source document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = defaultdict(list)\n",
    "for prev, current in zip(document, document[1:]):\n",
    "    transitions[prev].append(current)\n",
    "    \n",
    "def generate_using_bigrams() -> str:\n",
    "    current = \".\"\n",
    "    result = []\n",
    "    while True:\n",
    "        next_word_candidates = transitions[current]\n",
    "        current = random.choice(next_word_candidates)\n",
    "        result.append(current)\n",
    "        if current == \".\": return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It' s Dynamo and find out what can create animations that analyzed the existence of time .\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_text = generate_using_bigrams()\n",
    "bi_gram_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using trigrams, which are triplets of consecutive words, to see if we can create sentences that a little more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_transitions = defaultdict(list)\n",
    "starts = []\n",
    "\n",
    "for prev, current, next in zip(document, document[1:], document[2:]):\n",
    "\n",
    "    if prev == \".\":              # if the previous \"word\" was a period\n",
    "        starts.append(current)   # then this is a start word\n",
    "\n",
    "    trigram_transitions[(prev, current)].append(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_using_trigrams() -> str:\n",
    "    current = random.choice(starts)   # choose a random starting word\n",
    "    prev = \".\"                        # and precede it with a '.'\n",
    "    result = [current]\n",
    "    while True:\n",
    "        next_word_candidates = trigram_transitions[(prev, current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "\n",
    "        prev, current = current, next_word\n",
    "        result.append(current)\n",
    "\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are many packages for plotting and presenting data .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_gram_text = generate_using_trigrams()\n",
    "tri_gram_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
