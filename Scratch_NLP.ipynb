{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Level Look at the Basics of NLP \n",
    "#### This is a notebook based on the NLP chapter in \"Data Science from Scratch\" by Joel Grus. Please check out it out the book here:\n",
    "https://learning.oreilly.com/library/view/data-science-from/9781492041122/\n",
    "\n",
    "#### Or his blog here:\n",
    "https://joelgrus.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the Requests and Beautiful soup livraries to get some data. Here we are going to grab some data from an essay written by Mike Loukides titled \"What is Data Science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "\n",
    "url = \"https://www.oreilly.com/ideas/what-is-data-science\"\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look a the data we have, we need to get at the article body by finding the div with the class \"main-post-radar-content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find(\"div\", \"main-post-radar-content\")   # find article-body div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is far from clean as most data you will get so lets do some basic cleaning. First we will clean some of the apostrophes that are character \"â\" and replace them with a normal apostrophes with a function calles fix_unicode. Next we will want to create a sequence (list) of words and use the \".\" as a way of marking where each sentence ends.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_apostrophes(text: str) -> str:\n",
    "    return text.replace(\"â\", \"'\")\n",
    "\n",
    "regex = r\"[\\w']+|[\\.]\"                      \n",
    "document = []\n",
    "\n",
    "for paragraph in content(\"p\"):\n",
    "    words = re.findall(regex, fix_apostrophes(paragraph.text))\n",
    "    document.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"We'\",\n",
       " 've',\n",
       " 'all',\n",
       " 'heard',\n",
       " 'it',\n",
       " 'according',\n",
       " 'to',\n",
       " 'Hal',\n",
       " 'Varian',\n",
       " 'statistics']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a bigram model we can, given some starting word, can randomly choose one of one of the words that follow it in the source document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = defaultdict(list)\n",
    "for prev, current in zip(document, document[1:]):\n",
    "    transitions[prev].append(current)\n",
    "    \n",
    "def generate_using_bigrams() -> str:\n",
    "    current = \".\"\n",
    "    result = []\n",
    "    while True:\n",
    "        next_word_candidates = transitions[current]\n",
    "        current = random.choice(next_word_candidates)\n",
    "        result.append(current)\n",
    "        if current == \".\": return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It' s Dynamo and find out what can create animations that analyzed the existence of time .\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_text = generate_using_bigrams()\n",
    "bi_gram_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using trigrams, which are triplets of consecutive words, to see if we can create sentences that a little more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_transitions = defaultdict(list)\n",
    "starts = []\n",
    "\n",
    "for prev, current, next in zip(document, document[1:], document[2:]):\n",
    "\n",
    "    if prev == \".\":              # if the previous \"word\" was a period\n",
    "        starts.append(current)   # then this is a start word\n",
    "\n",
    "    trigram_transitions[(prev, current)].append(next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_using_trigrams() -> str:\n",
    "    current = random.choice(starts)   # choose a random starting word\n",
    "    prev = \".\"                        # and precede it with a '.'\n",
    "    result = [current]\n",
    "    while True:\n",
    "        next_word_candidates = trigram_transitions[(prev, current)]\n",
    "        next_word = random.choice(next_word_candidates)\n",
    "\n",
    "        prev, current = current, next_word\n",
    "        result.append(current)\n",
    "\n",
    "        if current == \".\":\n",
    "            return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are many packages for plotting and presenting data .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_gram_text = generate_using_trigrams()\n",
    "tri_gram_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
